import pandas as pd
import numpy as np
import os
from sklearn.ensemble import RandomForestRegressor, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import mean_squared_error, classification_report, roc_auc_score
from sklearn.pipeline import Pipeline
import joblib
from config import OUTPUT_PATH, TARGET_YEAR

# åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
MODEL_PATH = os.path.join(OUTPUT_PATH, "models/")
os.makedirs(MODEL_PATH, exist_ok=True)

def train_employment_change_model(df: pd.DataFrame) -> tuple:
    """
    è®­ç»ƒå°±ä¸šå˜åŒ–ç‡é¢„æµ‹æ¨¡å‹
    :param df: é¢„å¤„ç†åçš„æ•°æ®é›†
    :return: è®­ç»ƒå¥½çš„æ¨¡å‹å’Œè¯„ä¼°æŒ‡æ ‡
    """
    # é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡å˜é‡
    features = [
        "automation_risk_norm", "salary_usd_norm", "experience_years_norm",
        "remote_ratio_norm", "ai_impact_level_norm",
        "industry_encoded", "country_encoded", "education_encoded"
    ]
    features = [f for f in features if f in df.columns]
    target = "employment_change_rate"
    
    # å»é™¤ç›®æ ‡å˜é‡ä¸ºç©ºçš„æ ·æœ¬
    df_model = df.dropna(subset=[target] + features)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        df_model[features], df_model[target], test_size=0.2, random_state=42
    )
    
    # å®šä¹‰æ¨¡å‹ pipeline
    model = Pipeline([
        ("regressor", RandomForestRegressor(random_state=42))
    ])
    
    # ç½‘æ ¼æœç´¢å‚æ•°
    param_grid = {
        "regressor__n_estimators": [100, 200],
        "regressor__max_depth": [None, 10, 20],
        "regressor__min_samples_split": [2, 5]
    }
    
    # ç½‘æ ¼æœç´¢ä¼˜åŒ–æ¨¡å‹
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring="neg_mean_squared_error")
    grid_search.fit(X_train, y_train)
    
    # è¯„ä¼°æ¨¡å‹
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    
    # ä¿å­˜æ¨¡å‹
    model_path = os.path.join(MODEL_PATH, "employment_change_model.pkl")
    joblib.dump(best_model, model_path)
    print(f"ğŸ“¦ å°±ä¸šå˜åŒ–é¢„æµ‹æ¨¡å‹å·²ä¿å­˜ï¼š{model_path}")
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        "feature": features,
        "importance": best_model.named_steps["regressor"].feature_importances_
    }).sort_values(by="importance", ascending=False)
    
    return best_model, {"rmse": rmse, "feature_importance": feature_importance}

def train_automation_risk_model(df: pd.DataFrame) -> tuple:
    """
    è®­ç»ƒè‡ªåŠ¨åŒ–é£é™©åˆ†ç±»æ¨¡å‹ï¼ˆé¢„æµ‹é«˜é£é™©å·¥ä½œï¼‰
    :param df: é¢„å¤„ç†åçš„æ•°æ®é›†
    :return: è®­ç»ƒå¥½çš„æ¨¡å‹å’Œè¯„ä¼°æŒ‡æ ‡
    """
    # é€‰æ‹©ç‰¹å¾å’Œç›®æ ‡å˜é‡
    features = [
        "salary_usd_norm", "experience_years_norm", "remote_ratio_norm",
        "ai_impact_level_norm", "employment_change_rate",
        "industry_encoded", "country_encoded", "education_encoded"
    ]
    features = [f for f in features if f in df.columns]
    # ç›®æ ‡å˜é‡ï¼šæ˜¯å¦ä¸ºé«˜é£é™©å²—ä½
    target = "is_high_risk"
    df[target] = (df["risk_level"] == "high").astype(int)
    
    # å»é™¤ç›®æ ‡å˜é‡ä¸ºç©ºçš„æ ·æœ¬
    df_model = df.dropna(subset=[target] + features)
    
    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        df_model[features], df_model[target], test_size=0.2, random_state=42, stratify=df_model[target]
    )
    
    # å®šä¹‰æ¨¡å‹ pipeline
    model = Pipeline([
        ("classifier", GradientBoostingClassifier(random_state=42))
    ])
    
    # ç½‘æ ¼æœç´¢å‚æ•°
    param_grid = {
        "classifier__n_estimators": [100, 200],
        "classifier__max_depth": [3, 5, 10],
        "classifier__learning_rate": [0.01, 0.1]
    }
    
    # ç½‘æ ¼æœç´¢ä¼˜åŒ–æ¨¡å‹
    grid_search = GridSearchCV(model, param_grid, cv=5, scoring="roc_auc")
    grid_search.fit(X_train, y_train)
    
    # è¯„ä¼°æ¨¡å‹
    best_model = grid_search.best_estimator_
    y_pred = best_model.predict(X_test)
    y_pred_proba = best_model.predict_proba(X_test)[:, 1]
    
    # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    report = classification_report(y_test, y_pred)
    
    # ä¿å­˜æ¨¡å‹
    model_path = os.path.join(MODEL_PATH, "automation_risk_model.pkl")
    joblib.dump(best_model, model_path)
    print(f"ğŸ“¦ è‡ªåŠ¨åŒ–é£é™©é¢„æµ‹æ¨¡å‹å·²ä¿å­˜ï¼š{model_path}")
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        "feature": features,
        "importance": best_model.named_steps["classifier"].feature_importances_
    }).sort_values(by="importance", ascending=False)
    
    return best_model, {"roc_auc": roc_auc, "classification_report": report, "feature_importance": feature_importance}

def predict_future_employment(df: pd.DataFrame, model=None) -> pd.DataFrame:
    """
    é¢„æµ‹æœªæ¥å°±ä¸šå¸‚åœºå˜åŒ–
    :param df: é¢„å¤„ç†åçš„æ•°æ®é›†
    :param model: å¯é€‰ï¼Œå·²è®­ç»ƒå¥½çš„æ¨¡å‹
    :return: åŒ…å«é¢„æµ‹ç»“æœçš„DataFrame
    """
    if model is None:
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model_path = os.path.join(MODEL_PATH, "employment_change_model.pkl")
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
        model = joblib.load(model_path)
    
    # é€‰æ‹©ç‰¹å¾
    features = [
        "automation_risk_norm", "salary_usd_norm", "experience_years_norm",
        "remote_ratio_norm", "ai_impact_level_norm",
        "industry_encoded", "country_encoded", "education_encoded"
    ]
    features = [f for f in features if f in df.columns]
    
    # é¢„æµ‹å°±ä¸šå˜åŒ–ç‡
    df["predicted_employment_change"] = model.predict(df[features])
    
    # é¢„æµ‹2030å¹´å²—ä½æ•°é‡
    df["predicted_openings_2030"] = df.apply(
        lambda row: row["openings_2024"] * (1 + row["predicted_employment_change"]), axis=1
    )
    
    return df

def identify_high_risk_jobs(df: pd.DataFrame, model=None) -> pd.DataFrame:
    """
    è¯†åˆ«é«˜é£é™©å²—ä½
    :param df: é¢„å¤„ç†åçš„æ•°æ®é›†
    :param model: å¯é€‰ï¼Œå·²è®­ç»ƒå¥½çš„æ¨¡å‹
    :return: åŒ…å«é£é™©é¢„æµ‹çš„DataFrame
    """
    if model is None:
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        model_path = os.path.join(MODEL_PATH, "automation_risk_model.pkl")
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}ï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
        model = joblib.load(model_path)
    
    # é€‰æ‹©ç‰¹å¾
    features = [
        "salary_usd_norm", "experience_years_norm", "remote_ratio_norm",
        "ai_impact_level_norm", "employment_change_rate",
        "industry_encoded", "country_encoded", "education_encoded"
    ]
    features = [f for f in features if f in df.columns]
    
    # é¢„æµ‹é«˜é£é™©æ¦‚ç‡
    df["high_risk_probability"] = model.predict_proba(df[features])[:, 1]
    
    # é¢„æµ‹æ˜¯å¦ä¸ºé«˜é£é™©å²—ä½
    df["predicted_risk_level"] = model.predict(df[features])
    df["predicted_risk_level"] = df["predicted_risk_level"].map({0: "not_high", 1: "high"})
    
    return df